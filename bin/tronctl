#!/usr/bin/env python
"""Tron Control

Part of the command line interface to the tron daemon. Provides the interface
to controlling jobs and runs.
"""
import argparse
import datetime
import logging
import sys
from collections import defaultdict
from typing import Any
from typing import Dict
from typing import Optional
from typing import Tuple
from urllib.parse import urljoin

import argcomplete

from tron import __version_info__
from tron.commands import client
from tron.commands import cmd_utils
from tron.commands.client import RequestError
from tron.commands.cmd_utils import ExitCode
from tron.commands.cmd_utils import suggest_possibilities
from tron.commands.cmd_utils import tron_jobs_completer

COMMAND_HELP = (
    ("start", "Start the selected job, job run, or action. Creates a new job run if starting a job.",),
    ("rerun", "Start a new job run with the same start time command context as the given job run.",),
    (
        "retry",
        "Re-run a job action within an existing job run. Uses latest code/config except the command by default. Add --use-latest-command to use the latest command.",
    ),
    ("recover", "Ask Tron to start tracking an UNKNOWN action run again"),
    ("cancel", "Cancel the selected job run."),
    ("backfill", "Start job runs for a particular date range",),
    ("disable", "Disable selected job and cancel any outstanding runs"),
    ("enable", "Enable the selected job and schedule the next run"),
    ("fail", "Mark an UNKNOWN job or action as failed. Does not publish action triggers.",),
    ("success", "Mark an UNKNOWN job or action as having succeeded. Will publish action triggers.",),
    ("skip", "Skip a failed action, unblocks dependent actions. Does *not* publish action triggers.",),
    ("skip-and-publish", "Skip a failed action, unblocks dependent actions. *Does* publish action triggers.",),
    ("stop", "Stop the action run (SIGTERM)"),
    ("kill", "Force kill the action run (SIGKILL)"),
    ("move", "Rename a job"),
    ("publish", "Publish actionrun trigger to kick off downstream jobs"),
    ("discard", "Discard existing actionrun trigger"),
    ("version", "Print tron client and server versions"),
)

log = logging.getLogger("tronctl")


def parse_date(date_string):
    return datetime.datetime.strptime(date_string, "%Y-%m-%d")


def parse_cli():
    parser = cmd_utils.build_option_parser()

    subparsers = parser.add_subparsers(dest="command", title="commands", help="Tronctl command to run",)
    cmd_parsers = {}
    for cmd_name, desc in COMMAND_HELP:
        cmd_parsers[cmd_name] = subparsers.add_parser(cmd_name, help=desc, description=desc)
        cmd_parsers[cmd_name].add_argument(
            "id", nargs="*", help="job name, job run id, or action id",
        ).completer = cmd_utils.tron_jobs_completer

    # start
    cmd_parsers["start"].add_argument(
        "--run-date", type=parse_date, dest="run_date", help="What the run-date should be set to",
    )

    # backfill
    backfill_parser = cmd_parsers["backfill"]
    mutex_dates_group = backfill_parser.add_mutually_exclusive_group(required=True)
    mutex_dates_group.add_argument(
        "--start-date", type=parse_date, dest="start_date", help="First run-date to backfill",
    )
    backfill_parser.add_argument(
        "--end-date",
        type=parse_date,
        dest="end_date",
        help=(
            "Last run-date to backfill (note: many jobs operate on date-1), "
            "assuming --start-date is set. Defaults to today."
        ),
    )
    backfill_parser.add_argument(
        "--descending",
        action="store_true",
        default=False,
        help=(
            "If set, backfill from end date to start date. Otherwise, "
            "the default is to backfill from start date to end date."
        ),
    )
    mutex_dates_group.add_argument(
        "--dates",
        type=lambda v: [parse_date(date_str.strip()) for date_str in v.split(",")],
        dest="dates",
        help=(
            "List of comma-separated dates to run backfills on. "
            "Backfills will be executed for dates in the order they are presented."
        ),
    )
    backfill_parser.add_argument(
        "--dry-run",
        action="store_true",
        default=False,
        help="Prints the equivalent `tronctl start` commands for the backfill",
    )

    # retry
    cmd_parsers["retry"].add_argument(
        "--use-latest-command",
        action="store_true",
        default=False,
        help="Use the latest command in tronfig rather than the original command when the action run was created",
    )

    argcomplete.autocomplete(parser)
    args = parser.parse_args()

    return args


def request(url: str, data: Dict[str, Any], headers=None, method=None) -> bool:
    response = client.request(url, data=data, headers=headers, method=method)
    if response.error:
        print(f"Error: {response.content}")
        return False
    print(response.content.get("result", "OK"))
    return True


def event_publish(args):
    for event in args.id:
        yield request(
            urljoin(args.server, "/api/events"), dict(command="publish", event=event),
        )


def event_discard(args):
    for event in args.id:
        yield request(
            urljoin(args.server, "/api/events"), dict(command="discard", event=event),
        )


def _get_triggers_for_action(server: str, action_identifier: str) -> Optional[Tuple[str, ...]]:
    try:
        namespace, job_name, run_number, action_name = action_identifier.split(".")
    except ValueError:
        print(
            f"Unable to fully decompose {action_identifier}: expected an identifier of the form (namespace).(job).(run).(action)"
        )
        return None

    trigger_response = client.request(
        uri=urljoin(server, f"/api/jobs/{namespace}.{job_name}/{run_number}/{action_name}",),
    )
    if trigger_response.error:
        print(f"Unable to fetch downstream triggers for {action_identifier}: {trigger_response.error}")
        return None

    # triggers are returned by the API as comma-separated values with a space after every comma, which is
    # not automation-friendly - thus the non-standard multi-character split
    triggers = trigger_response.content.get("trigger_downstreams", "").split(", ")

    # the API will return an empty string for actions with no triggers to emit, but splitting '' yields [''],
    # so we want to make sure that we return an empty iterable in this case
    return tuple(f"{namespace}.{job_name}.{action_name}.{trigger}" for trigger in triggers if trigger)


def control_objects(args: argparse.Namespace):
    tron_client = client.Client(args.server)
    url_index = tron_client.index()
    for identifier in args.id:
        try:
            tron_id = client.get_object_type_from_identifier(url_index, identifier,)
        except ValueError as e:
            possibilities = list(tron_jobs_completer(prefix="", client=tron_client),)
            suggestions = suggest_possibilities(word=identifier, possibilities=possibilities,)
            raise SystemExit(f"Error: {e}{suggestions}")

        if args.command == "skip-and-publish":
            # this command is more of a pseudo-command - skip and publish are handled in two different resources
            # and changing the API would be painful, so instead we call skip + publish separately from the client
            # (i.e., this file) to implement this functionality
            if request(url=urljoin(args.server, tron_id.url), data={"command": "skip"},):
                # a single action can have 0..N triggers to publish and these can be arbitrarily named, so we need to
                # query the API and figure out what triggers exist
                triggers = _get_triggers_for_action(server=args.server, action_identifier=identifier)
                if triggers is None:
                    print("Encountered error getting triggers to publish.")
                    yield False
                elif not triggers:
                    print(f"{identifier} has no triggers to publish.")
                    # TODO: should we check this up-front and refuse to skip if there are no triggers that will be
                    # published rather than carry on under the assumption that the user copy-pasted/typo'd the identifier?
                    yield True

                # TODO: this loop should use event_publish(), but we'd need to refactor how the CLI works and stop passing
                # around the full set of args everywhere to do so
                for trigger in triggers:
                    yield request(
                        url=urljoin(args.server, "/api/events"), data={"command": "publish", "event": trigger},
                    )
            else:
                print(f"Unable to skip {identifier}.")
                yield False

        else:
            data = dict(command=args.command)
            if args.command == "start" and args.run_date:
                data["run_time"] = str(args.run_date)
            if args.command == "retry":
                data["use_latest_command"] = int(args.use_latest_command)
            yield request(urljoin(args.server, tron_id.url), data)


def move(args):
    try:
        old_name = args.id[0]
        new_name = args.id[1]
    except IndexError as e:
        raise SystemExit(f"Error: Move command needs two arguments.\n{e}")

    tron_client = client.Client(args.server)
    url_index = tron_client.index()
    job_index = url_index["jobs"]
    if old_name not in job_index.keys():
        raise SystemExit(f"Error: {old_name} doesn't exist")
    if new_name in job_index.keys():
        raise SystemExit(f"Error: {new_name} exists already")

    data = dict(command="move", old_name=old_name, new_name=new_name)
    yield request(urljoin(args.server, "/api/jobs"), data)


def backfill(args):
    if not args.id:
        print("Error: must provide at least one id argument")
        yield False

    if args.start_date:
        if args.end_date is None:
            args.end_date = datetime.datetime.today()
        dates = get_dates_for_backfill(args.start_date, args.end_date, descending=args.descending,)
    else:
        dates = args.dates

    run_id = args.id[0]
    if args.dry_run:
        date_strs = [d.date().isoformat() for d in dates]
        _backfill_dry_run(run_id, date_strs)
        yield True
    else:
        for date in dates:
            # this is a hack since `control_objects` requires an arg namespace
            start_args = argparse.Namespace()
            for arg_name in ["cluster_name", "save_config", "server", "verbose"]:
                setattr(start_args, arg_name, getattr(args, arg_name))
            start_args.command = "start"
            start_args.id = [run_id]
            start_args.run_date = date

            print(f"Running backfill for {run_id} for {date}")
            yield from COMMANDS["start"](start_args)


def _backfill_dry_run(job, dates):
    print(f"Please run the following {len(dates)} commands:")
    print("")
    for date in dates:
        print(f"tronctl start {job} --run-date {date}")
    print("")
    print("Note that many jobs operate on the previous day's data.")


def get_dates_for_backfill(start_date, end_date, descending=False):
    dates = []
    delta = end_date - start_date
    for i in range(delta.days + 1):
        dates.append(start_date + datetime.timedelta(i))
    if descending:
        dates.reverse()
    return dates


def tron_version(args):
    local_version = ".".join(map(str, __version_info__))
    print(f"Tron client version: {local_version}")
    response = client.request(urljoin(args.server, "/api/status"))
    if response.error:
        print(f"Error: {response.content}")
        yield
    server_version = response.content.get("version", "unknown")
    print(f"Tron server version: {server_version}")
    if server_version != local_version:
        print("Warning: client and server versions should match")
        yield
    yield True


COMMANDS = defaultdict(
    lambda: control_objects,
    publish=event_publish,
    discard=event_discard,
    backfill=backfill,
    move=move,
    version=tron_version,
)


def main():
    """run tronctl"""
    args = parse_cli()
    cmd_utils.setup_logging(args)
    cmd_utils.load_config(args)
    cmd = COMMANDS[args.command]
    try:
        for ret in cmd(args):
            if not ret:
                sys.exit(ExitCode.fail)
    except RequestError as err:
        print(
            f"Error connecting to the tron server ({args.server}): {err}", file=sys.stderr,
        )
        sys.exit(ExitCode.fail)


if __name__ == "__main__":
    main()
